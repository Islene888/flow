import urllib.parse
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError
from state2.growthbook_fetcher.experiment_tag_all_parameters import get_experiment_details_by_tag


def insert_experiment_data_to_wide_active_table(tag):
    try:
        # è·å–å®éªŒçš„è¯¦ç»†ä¿¡æ¯
        experiment_data = get_experiment_details_by_tag(tag)
        if not experiment_data:
            print(f"æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ ‡ç­¾ '{tag}' çš„å®éªŒæ•°æ®ï¼")
            return

        experiment_name = experiment_data['experiment_name']
        start_time = experiment_data['phase_start_time']
        end_time = experiment_data['phase_end_time']

        # æ—¶é—´æ ¼å¼åŒ–
        formatted_start_time = start_time.strftime('%Y-%m-%d')
        formatted_end_time = end_time.strftime('%Y-%m-%d')

        # æ•°æ®åº“è¿æ¥
        password = urllib.parse.quote_plus("flowgpt@2024.com")
        DATABASE_URL = f"mysql+pymysql://bigdata:{password}@3.135.224.186:9030/flow_ab_test?charset=utf8mb4"
        engine = create_engine(DATABASE_URL)

        table_name = f"tbl_wide_user_retention_active_{tag}"

        # åˆ›å»ºå®½è¡¨ï¼ˆå¢åŠ  country å­—æ®µï¼‰
        create_table_query = f"""
        CREATE TABLE IF NOT EXISTS {table_name} (
            dt DATE,
            variation VARCHAR(255),
            country VARCHAR(64),
            new_users INT,
            d1 INT,
            d3 INT,
            d7 INT,
            d15 INT,
            total_assigned INT
        );
        """

        # åˆ›å»ºè¡¨
        with engine.connect() as conn:
            conn.execute(text(create_table_query))
        print(f"âœ… å®½è¡¨ {table_name} å·²æˆåŠŸåˆ›å»ºï¼")

        # æ¸…ç©ºå†å²æ•°æ®
        with engine.connect() as conn:
            conn.execute(text(f"TRUNCATE TABLE {table_name};"))
        print(f"âœ… è¡¨ {table_name} å·²æˆåŠŸæ¸…ç©ºåŸæœ‰æ•°æ®ï¼")

        # åˆ†æ‰¹æ’å…¥
        batch_count = 100
        for i in range(batch_count):
            insert_query = f"""
            INSERT INTO {table_name} (dt, variation, country, new_users, d1, d3, d7, d15, total_assigned)
            SELECT
            /*+ SET_VAR(query_timeout = 60000) */
                base.active_date AS dt,
                e.variation,
                e.country,
                COUNT(DISTINCT base.user_id) AS new_users,
                COUNT(DISTINCT CASE WHEN d1.user_id IS NOT NULL THEN base.user_id END) AS d1,
                COUNT(DISTINCT CASE WHEN d3.user_id IS NOT NULL THEN base.user_id END) AS d3,
                COUNT(DISTINCT CASE WHEN d7.user_id IS NOT NULL THEN base.user_id END) AS d7,
                COUNT(DISTINCT CASE WHEN d15.user_id IS NOT NULL THEN base.user_id END) AS d15,
                MAX(COALESCE(ta.total_assigned, 0)) AS total_assigned
            FROM (
                SELECT user_id, active_date
                FROM flow_wide_info.tbl_wide_active_user_app_info
                WHERE active_date BETWEEN '{formatted_start_time}' AND '{formatted_end_time}'
                  AND keep_alive_flag = 1
                  AND user_id IS NOT NULL AND user_id != ''
                  AND MOD(CRC32(user_id), {batch_count}) = {i}
                GROUP BY user_id, active_date
            ) base
            LEFT JOIN (
                SELECT t.user_id, t.variation, geo.country
                FROM (
                    SELECT user_id, CAST(variation_id AS CHAR) AS variation,
                           ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY timestamp_assigned ASC) AS rn
                    FROM flow_wide_info.tbl_wide_experiment_assignment_hi
                    WHERE experiment_id = '{experiment_name}'
                      AND timestamp_assigned BETWEEN '{formatted_start_time}' AND '{formatted_end_time}'
                ) t
                LEFT JOIN (
                    SELECT user_id,
                           MAX(get_json_string(geo, '$.country')) AS country
                    FROM flowgpt.tbl_event_app
                    WHERE user_id IS NOT NULL AND user_id != ''
                    GROUP BY user_id
                ) geo ON t.user_id = geo.user_id
                WHERE rn = 1
            ) e ON base.user_id = e.user_id
            LEFT JOIN (
                SELECT user_id, active_date
                FROM flow_wide_info.tbl_wide_active_user_app_info
                WHERE active_date BETWEEN DATE_ADD('{formatted_start_time}', INTERVAL 1 DAY)
                                        AND DATE_ADD('{formatted_end_time}', INTERVAL 15 DAY)
                  AND keep_alive_flag = 1
                GROUP BY user_id, active_date
            ) d1 ON base.user_id = d1.user_id AND DATEDIFF(d1.active_date, base.active_date) = 1
            LEFT JOIN (
                SELECT user_id, active_date
                FROM flow_wide_info.tbl_wide_active_user_app_info
                WHERE active_date BETWEEN DATE_ADD('{formatted_start_time}', INTERVAL 3 DAY)
                                        AND DATE_ADD('{formatted_end_time}', INTERVAL 15 DAY)
                  AND keep_alive_flag = 1
                GROUP BY user_id, active_date
            ) d3 ON base.user_id = d3.user_id AND DATEDIFF(d3.active_date, base.active_date) = 3
            LEFT JOIN (
                SELECT user_id, active_date
                FROM flow_wide_info.tbl_wide_active_user_app_info
                WHERE active_date BETWEEN DATE_ADD('{formatted_start_time}', INTERVAL 7 DAY)
                                        AND DATE_ADD('{formatted_end_time}', INTERVAL 15 DAY)
                  AND keep_alive_flag = 1
                GROUP BY user_id, active_date
            ) d7 ON base.user_id = d7.user_id AND DATEDIFF(d7.active_date, base.active_date) = 7
            LEFT JOIN (
                SELECT user_id, active_date
                FROM flow_wide_info.tbl_wide_active_user_app_info
                WHERE active_date BETWEEN DATE_ADD('{formatted_start_time}', INTERVAL 15 DAY)
                                        AND DATE_ADD('{formatted_end_time}', INTERVAL 15 DAY)
                  AND keep_alive_flag = 1
                GROUP BY user_id, active_date
            ) d15 ON base.user_id = d15.user_id AND DATEDIFF(d15.active_date, base.active_date) = 15
            LEFT JOIN (
                SELECT DATE(timestamp_assigned) AS assign_date,
                       CAST(variation_id AS CHAR) AS variation,
                       COUNT(DISTINCT user_id) AS total_assigned
                FROM flow_wide_info.tbl_wide_experiment_assignment_hi
                WHERE experiment_id = '{experiment_name}'
                GROUP BY DATE(timestamp_assigned), CAST(variation_id AS CHAR)
            ) ta ON ta.assign_date = base.active_date AND ta.variation = e.variation
            WHERE e.variation IS NOT NULL AND e.country IS NOT NULL
            GROUP BY base.active_date, e.variation, e.country
            ORDER BY base.active_date, e.variation, e.country;
            """

            try:
                with engine.connect() as conn:
                    conn.execute(text(insert_query))
                print(f"âœ… åˆ†æ‰¹ {i + 1}/{batch_count} æ•°æ®å·²æˆåŠŸå†™å…¥ {table_name}ï¼")
            except SQLAlchemyError as e:
                print(f"ğŸš¨ åˆ†æ‰¹ {i + 1}/{batch_count} æ•°æ®æ’å…¥å¤±è´¥: {e}")

        # èšåˆæ±‡æ€»
        merge_query = f"""
        SELECT
            dt,
            variation,
            country,
            SUM(new_users) AS new_users,
            SUM(d1) AS d1,
            SUM(d3) AS d3,
            SUM(d7) AS d7,
            SUM(d15) AS d15,
            MAX(total_assigned) AS total_assigned
        FROM {table_name}
        GROUP BY dt, variation, country;
        """

        aggregated_data = []
        try:
            with engine.connect() as conn:
                result = conn.execute(text(merge_query))
                aggregated_data = result.mappings().all()
            print("âœ… æ•°æ®èšåˆæˆåŠŸï¼")
        except SQLAlchemyError as e:
            print(f"ğŸš¨ æ•°æ®èšåˆå¤±è´¥: {e}")

        # æ¸…ç©ºåŸå§‹åˆ†æ‰¹æ•°æ®ï¼Œæ’å…¥èšåˆæ•°æ®
        try:
            with engine.connect() as conn:
                conn.execute(text(f"TRUNCATE TABLE {table_name};"))
            print(f"âœ… è¡¨ {table_name} å·²æˆåŠŸæ¸…ç©ºï¼Œå‡†å¤‡å†™å…¥èšåˆåçš„æ•°æ®ï¼")
        except SQLAlchemyError as e:
            print(f"ğŸš¨ æ¸…ç©ºæ•°æ®å¤±è´¥: {e}")

        insert_row_query = f"""
        INSERT INTO {table_name} (dt, variation, country, new_users, d1, d3, d7, d15, total_assigned)
        VALUES (:dt, :variation, :country, :new_users, :d1, :d3, :d7, :d15, :total_assigned);
        """

        try:
            with engine.begin() as conn:
                conn.execute(text(insert_row_query), aggregated_data)
            print(f"âœ… èšåˆæ•°æ®æˆåŠŸæ’å…¥ {table_name}ï¼")
        except SQLAlchemyError as e:
            print(f"ğŸš¨ èšåˆæ•°æ®æ’å…¥å¤±è´¥: {e}")

    except Exception as e:
        print(f"ğŸš¨ æ‰§è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    tag = "trans_pt"  # æ ¹æ®å®é™…æ ‡ç­¾ä¿®æ”¹
    insert_experiment_data_to_wide_active_table(tag)