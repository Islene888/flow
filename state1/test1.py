import urllib.parse
from sqlalchemy import create_engine, text
import pandas as pd
import numpy as np
import scipy.stats as stats
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib
from sqlalchemy.exc import SQLAlchemyError
import re
from datetime import datetime

# âœ… è§£å†³ Matplotlib ä¸­æ–‡ä¹±ç 
matplotlib.rcParams['font.sans-serif'] = ['Arial Unicode MS']
matplotlib.rcParams['axes.unicode_minus'] = False

# å¯¹å¯†ç è¿›è¡Œ URL ç¼–ç 
password = urllib.parse.quote_plus("flowgpt@2024.com")

# æ„é€ æ•°æ®åº“è¿æ¥ URL
DATABASE_URL = f"mysql+pymysql://bigdata:{password}@18.188.196.105:9030/flow_test"

# åˆ›å»ºæ•°æ®åº“è¿æ¥
engine = create_engine(DATABASE_URL)


# å‡½æ•°ï¼šæå–å®éªŒçš„æ—¥æœŸèŒƒå›´å¹¶è®¡ç®—å¤©æ•°
def get_experiment_params():
    query = """
    SELECT experiment_name, date_created, date_updated, control_group_key, variations
    FROM `tbl_experiment_data`
    WHERE experiment_name IS NOT NULL
    """
    experiment_data = pd.read_sql(query, engine)

    if experiment_data.empty:
        raise ValueError("No experiments found in `tbl_experiment_data`")

    experiment_params = []
    for _, row in experiment_data.iterrows():
        experiment_name = row['experiment_name']
        date_created = row['date_created']
        date_updated = row['date_updated']
        control_group_key = row['control_group_key']
        variations = row['variations']

        # æ‰“å°æ¯ä¸ªå®éªŒçš„åŸºæœ¬ä¿¡æ¯ï¼Œæ–¹ä¾¿è°ƒè¯•
        print(f"Processing experiment: {experiment_name}")
        print(f"Date Created: {date_created}, Date Updated: {date_updated}")

        # å¤„ç†æ¯«ç§’éƒ¨åˆ†
        start_date = datetime.strptime(str(date_created).split('.')[0], '%Y-%m-%d %H:%M:%S')
        end_date = datetime.strptime(str(date_updated).split('.')[0], '%Y-%m-%d %H:%M:%S')

        experiment_days = (end_date - start_date).days + 1

        experiment_params.append({
            "experiment_name": experiment_name,
            "start_date": start_date,
            "end_date": end_date,
            "experiment_days": experiment_days,
            "control_group_key": control_group_key,
            "variations": variations
        })

    return experiment_params


# å‡½æ•°ï¼šæ ¹æ®å®éªŒå‚æ•°åŠ¨æ€åˆ›å»ºè¡¨å¹¶æ’å…¥æ•°æ®
def create_and_insert_table(experiment_name, start_date, end_date, experiment_days):
    # åŠ¨æ€ç”Ÿæˆå¤©æ•°åˆ—
    days_columns = [f"d{i}" for i in range(1, experiment_days + 1)]

    # åŠ¨æ€ç”Ÿæˆè¡¨å
    table_name_filtered = f"tbl_user_engagement_filtered_{experiment_name}"
    print(table_name_filtered)

    table_name_results = f"tbl_new_retention_results_{experiment_name}"
    print(table_name_results)

    # æ‰“å°ç”Ÿæˆçš„è¡¨å
    print(f"Creating/Verifying tables: {table_name_filtered}, {table_name_results}")

    # SQL æŸ¥è¯¢ï¼šåˆ›å»ºæ–°è¡¨
    create_table_query = f"""
    CREATE TABLE IF NOT EXISTS `{table_name_filtered}` (
        dt DATE,
        variations VARCHAR(255),
        users INT,
        {', '.join([f'{day} INT' for day in days_columns])}
    );

    CREATE TABLE IF NOT EXISTS `{table_name_results}` (
        dt DATE,
        day INT,
        variations VARCHAR(255),
        users INT,
        retained INT,
        retention_rate DOUBLE,
        ci_lower DOUBLE,
        ci_upper DOUBLE,
        control_rate DOUBLE,
        exp_rate DOUBLE,
        uplift DOUBLE,  
        uplift_ci_lower DOUBLE,  
        uplift_ci_upper DOUBLE,  
        z_score DOUBLE,  
        p_value DOUBLE,  
        retention_rate_baseline DOUBLE
    );
    """

    # æ‰§è¡Œåˆ›å»ºè¡¨æ“ä½œ
    try:
        with engine.connect() as conn:
            conn.execute(text(create_table_query))
        print(f"âœ… Tables created or verified for {experiment_name}.")
    except SQLAlchemyError as e:
        print(f"ğŸš¨ SQL Error: {e}")
        return

    insert_query = f"""
        INSERT INTO `{table_name_filtered}` (dt, variation, users, {', '.join(days_columns)})
        SELECT 
            u.first_visit_date AS dt, 
            e.variation,  -- æ³¨æ„è¿™é‡Œä½¿ç”¨çš„æ˜¯ variation
            COUNT(DISTINCT u.user_id) AS users,
            {', '.join([f'COUNT(DISTINCT CASE WHEN a.active_date = DATE_ADD(u.first_visit_date, INTERVAL {i} DAY) THEN a.user_id END) AS d{i}' for i in range(1, experiment_days + 1)])}
        FROM
            (SELECT
                user_id,
                DATE(first_visit_date) AS first_visit_date
            FROM
                flow_wide_info.tbl_wide_user_first_visit_app_info
            WHERE
                first_visit_date BETWEEN '{start_date.strftime('%Y-%m-%d')}' AND '{end_date.strftime('%Y-%m-%d')}') u
        LEFT JOIN
            (SELECT
                u.user_id,
                u.first_visit_date,
                DATE(FROM_UNIXTIME(a.ingest_timestamp / 1000, '%%Y-%%m-%%d')) AS active_date
            FROM
                flow_wide_info.tbl_wide_user_first_visit_app_info u
            JOIN
                flow_wide_info.tbl_wide_backend_detail_hi a ON u.user_id = a.user_id
            WHERE
                a.event_name = 'Chat_LLM'
                AND a.device_type = 'MOBILE'
                AND DATE(FROM_UNIXTIME(a.ingest_timestamp / 1000, '%%Y-%%m-%%d')) BETWEEN u.first_visit_date AND '{end_date.strftime('%Y-%m-%d')}') a
        ON u.user_id = a.user_id
        LEFT JOIN
            (SELECT
                user_id,
                CAST(variation_id AS CHAR) AS variation  -- æ³¨æ„è¿™é‡Œç”¨çš„æ˜¯ variation
            FROM
                flow_wide_info.tbl_wide_experiment_assignment_hi
            WHERE
                experiment_name = '{experiment_name}'
                AND timestamp_assigned BETWEEN '{start_date.strftime('%Y-%m-%d')} 12:00:00' AND '{end_date.strftime('%Y-%m-%d')} 12:00:00') e
        ON u.user_id = e.user_id
        GROUP BY
            u.first_visit_date, e.variation
        ORDER BY 
            u.first_visit_date;
    """

    # æ‰§è¡Œæ’å…¥æ“ä½œ
    try:
        with engine.connect() as conn:
            conn.execute(text(insert_query))
        print(f"âœ… Data inserted for {experiment_name}.")
    except SQLAlchemyError as e:
        print(f"ğŸš¨ SQL Error during data insertion: {e}")


# è·å–å®éªŒå‚æ•°
experiment_params = get_experiment_params()

# éå†æ¯ä¸ªå®éªŒï¼Œè¿è¡Œè®¡ç®—
for params in experiment_params:
    experiment_name = params["experiment_name"]
    start_date = params["start_date"]
    end_date = params["end_date"]
    experiment_days = params["experiment_days"]

    # æ‰“å°å®éªŒå‚æ•°
    print(f"Running for experiment: {experiment_name}")
    print(f"Start Date: {start_date}, End Date: {end_date}, Days: {experiment_days}")

    # åˆ›å»ºè¡¨å¹¶æ’å…¥æ•°æ®
    create_and_insert_table(experiment_name, start_date, end_date, experiment_days)

    # ä½¿ç”¨æ­£ç¡®çš„è¡¨å
    table_name_filtered = f"tbl_user_engagement_filtered_{experiment_name}"

    # åŠ¨æ€ç”ŸæˆæŸ¥è¯¢è¯­å¥
    query = f"""
    SELECT * FROM `{table_name_filtered}`
    ORDER BY dt ASC, CAST(variation AS UNSIGNED) ASC;
    """

    print(f"Running query: {query}")

    df = pd.read_sql(query, engine)

    # æ‰“å°æ•°æ®é¢„è§ˆ
    print(f"Data retrieved: {df.head()}")

    # å°† NaN æ›¿æ¢ä¸º SQL ä¸­çš„ NULL
    df = df.where(pd.notnull(df), None)

    if 'dt' not in df.columns:
        df['dt'] = pd.to_datetime(df['first_visit_date'])

    df["variations"] = df["variations"].astype(str)

    # åŠ¨æ€ç”Ÿæˆç•™å­˜ç‡è®¡ç®—è¿‡ç¨‹
    days_columns = [f"d{i}" for i in range(1, experiment_days + 1)]
    day_map = {f"d{i}": str(i) for i in range(1, experiment_days + 1)}

    results = []

    for _, row in df.iterrows():
        dt = row["dt"]
        variations = row["variations"]
        users = row["users"]

        if users > 0:
            for day in days_columns:
                day_num = day_map[day]
                retained = row[day]

                # è®¡ç®—ç•™å­˜ç‡
                retention_rate = np.float64(retained) / np.float64(users) if users > 0 else 0

                # è®¡ç®—æ ‡å‡†è¯¯å·®ï¼ˆæ ‡å‡†è¯¯ï¼‰
                se = np.sqrt((retention_rate * (1 - retention_rate)) / np.float64(users)) if users > 0 else 0

                # è®¡ç®—95%ç½®ä¿¡åŒºé—´
                ci_lower = retention_rate - 1.96 * se
                ci_upper = retention_rate + 1.96 * se

                # å°†ç»“æœæ·»åŠ åˆ°ç»“æœåˆ—è¡¨
                results.append({
                    "dt": dt,
                    "day": int(day_num),
                    "variations": variations,
                    "users": users,
                    "retained": retained,
                    "retention_rate": retention_rate,
                    "ci_lower": ci_lower,
                    "ci_upper": ci_upper
                })

        # å°†ç»“æœè½¬æ¢ä¸º DataFrame
        results_df = pd.DataFrame(results)

        # è®¡ç®—æ›´å¤šçš„ç»Ÿè®¡æ•°æ®
        for variations in results_df["variations"].unique():
            variation_data = results_df[results_df["variations"] == variations]

            # è®¡ç®—å¯¹ç…§ç»„çš„åŸºå‡†ç•™å­˜ç‡ï¼ˆå‡è®¾ç¬¬ä¸€ä¸ª variation ä½œä¸ºå¯¹ç…§ç»„ï¼‰
            if variations == results_df["variations"].unique()[0]:
                baseline_retention_rate = variation_data["retention_rate"].mean()
            else:
                baseline_retention_rate = results_df[results_df["variations"] == results_df["variations"].unique()[0]][
                    "retention_rate"].mean()

            # è®¡ç®—æå‡ï¼ˆUpliftï¼‰
            results_df["uplift"] = results_df["retention_rate"] - baseline_retention_rate
            results_df["uplift_ci_lower"] = results_df["ci_lower"] - baseline_retention_rate
            results_df["uplift_ci_upper"] = results_df["ci_upper"] - baseline_retention_rate

            # è®¡ç®— Z åˆ†æ•°å’Œ P å€¼
            results_df["z_score"] = (results_df["retention_rate"] - baseline_retention_rate) / np.sqrt(
                (baseline_retention_rate * (1 - baseline_retention_rate)) / results_df["users"])
            results_df["p_value"] = stats.norm.sf(abs(results_df["z_score"])) * 2  # åŒå°¾æ£€éªŒ

        # å°†ç»“æœå†™å…¥ç»“æœè¡¨
        insert_results_query = f"""
            INSERT INTO `{experiment_name}_new_retention_results` 
            (dt, day, variations, users, retained, retention_rate, ci_lower, ci_upper, control_rate, exp_rate, uplift, uplift_ci_lower, uplift_ci_upper, z_score, p_value, retention_rate_baseline)
            VALUES 
        """

        # å°† DataFrame ä¸­çš„ NaN æ›¿æ¢ä¸º SQL ä¸­çš„ NULLï¼ˆå³ Noneï¼‰
        df = df.replace({np.nan: None})

        # å¯¹è®¡ç®—çš„ç»“æœï¼Œä¹Ÿè¿›è¡ŒåŒæ ·çš„å¤„ç†
        results_df = results_df.replace({np.nan: None})

        # åœ¨æ’å…¥æ•°æ®åº“ä¹‹å‰ï¼Œç¡®ä¿æ²¡æœ‰ NaN å€¼
        insert_values = []
        for _, row in results_df.iterrows():
            insert_values.append(
                f"('{row['dt']}', {row['day']}, '{row['variations']}', {row['users']}, {row['retained']}, {row['retention_rate']}, {row['ci_lower']}, {row['ci_upper']}, {row['retention_rate_baseline']}, {row['retention_rate']}, {row['uplift']}, {row['uplift_ci_lower']}, {row['uplift_ci_upper']}, {row['z_score']}, {row['p_value']}, {row['retention_rate_baseline']})"
            )

        # å¤„ç†æ’å…¥æ•°æ®æ—¶çš„ None ä¸º NULL
        insert_values = [value.replace('None', 'NULL') for value in insert_values]

        # æ„å»ºå®Œæ•´çš„æ’å…¥æŸ¥è¯¢
        insert_values_query = insert_results_query + ", ".join(insert_values)

        # æ‰§è¡Œæ’å…¥æ“ä½œ
        try:
            with engine.connect() as conn:
                conn.execute(text(insert_values_query))
            print(f"âœ… Results inserted for {experiment_name}.")
        except SQLAlchemyError as e:
            print(f"ğŸš¨ SQL Error during result insertion: {e}")
